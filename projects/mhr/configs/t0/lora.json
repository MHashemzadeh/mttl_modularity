{
    "lora_randb_init": false,
    "lora_rank": 1,
    "lora_init_scale": 0.01,
    "lora_scaling_rank": 0,
    "lora_kaiming_init": false,
    "lora_warmup": false,
    "modify_modules": ".*SelfAttention|.*EncDecAttention|.*DenseReluDense",
    "model_modifier": "lora",
    "modify_layers": "q|k|v|o",
    "trainable_param_names": ".*lora_[ab].*",
    "adapters_learning_rate": 0.001
}